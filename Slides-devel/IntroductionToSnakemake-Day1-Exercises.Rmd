---
title: "Introduction to Snakemake"
subtitle: "Exercises"
author: "Daniel Fischer"
date: "6 June 2022"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float:
      toc_collapsed: true
    number_sections: true
    theme: lumen
    df_print: paged
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = FALSE)
```

# Exercise 1

## Setting up Computer environment

For warming up, please login to Puhti, navigate to the project scratch space (`/scratch/project_200XXXX`)

```{bash}
cd /scratch/project_200XXX
```

There, create a subfolder with your username

```{bash}
mkdir $USER
```

Activate the snakemake functionality (remember, it was part of the bioconda module)

```{bash}
module load bioconda/3
```

And test, if snakemake is available for you (e.g. by printing the version)

```{bash}
snakemake --version
```

# Exercise 2

## Own "Hello-World"

Create your own "Hello-World" workflow and run it.

The workflow file called `hello-world.smk` should contain something similar to this:

```{bash}
rule all:
    input: "hello-world.txt"
    
rule say_hello:
    output: "hello-world.txt"
    shell:"""
    echo 'Hello World!!!' > {output}
    """
```

And you can run it with this shell command

```{bash}
snakemake --cores 1  --snakefile hello-world.smk
```

## Create a two-stage workflow

This is a more advanced step. We learned, that Snakemake rules consist out of input, output and shell directives and that they can be thought of dependency graphs. The input of one rule should be the output of another rule.

In the next exercise, I would like you to think about a two-staged workflow. One example could be for example that you first create the file "hello-world" and in the next step/rule, you would take this file and translate the content to upper case, e.g. using this command:

`tr '[:lower:]' '[:upper:]' < hello-world.txt > HELLO-WORLD.txt`

Remember to use a rule `all` that contains the final file you want to receive and also to use `{input}` and `{output}` curly bracket notations in your `shell` directive.

The complete workflow would look e.g. like this:

```{python}
rule all:
    input: "HELLO-WORLD.txt"

rule say_hello:
    output: "hello-world.txt"
    shell:"""
    echo 'Hello World!!!' > hello-world.txt
    """

rule capitalise:
    input: "hello-world.txt"
    output: "HELLO-WORLD.txt"
    shell:"""
    tr '[:lower:]' '[:upper:]' < {input} > {output}
    """
```

# Exercise 3

## Download the exercise data
Run the bioinformatics example also for sample B and C. For that, we need to do a few things first. First, download the data into your user project folder that you created earlier, using these commands:

`cd /scratch/project_200XXX/$USER`

`wget https://github.com/snakemake/snakemake-tutorial-data/archive/v5.4.5.tar.gz`

`tar --wildcards -xf v5.4.5.tar.gz --strip 1 "*/data"`

and then we need to make bwa and samtools available via the module system like this

`module load gcc/9.1.0`

`module load bwa/0.7.17`

`module load samtools`

## Align B.fastq
In the slides, we had the workflow that aligns the data for the sample A.fastq. Now, try to adjust the script such, that you can align B.fastq.

The workflow look like this:

```{python}
rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/B.fastq"
    output:
        "mapped_reads/B.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"
```

and the bash command to run the workflow like this:

```{bash}
snakemake -c1 -s bwa_align.smk mapped_reads/B.bam
```

# Exercise 4

Adjust your alignment script also such, that you use wildcards (`{sample}`) instead of hard-coded filenames and run the alignemtn for all three samples A,B and C.

The adjusted script would look like this:

````{python}
rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"
```

and the bash command to start the workflow,looks e.g. like this:

```{bash}
snakemake -c1 -s bwa_align.smk mapped_reads/{A,B,C}.bam
```

After you prepared the three bam files, try to rerun the workflow again and check what Snakemake does.

That is what it will look like:

```{bash}
Building DAG of jobs...
Nothing to be done.
Complete log: /users/fischerd/tmp/fischerd/.snakemake/log/2022-06-01T135131.623828.snakemake.log
```

However, now assume that one of the input files was changed. You can simulate this, by 'touching' it like this:

`touch /scratch/project_200XXX/$USER/data/A.fastq`

Try to do that and rerun then the pipeline again.

# Exercise 5
First, add the sorting and indexing step to your workflow file.

It will look then like this:

```{bash}
rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:"""
      samtools sort -T sorted_reads/{wildcards.sample} \
               -O bam {input} > {output}
    """

rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"
```

Then prepare the DAG.

```{bash}
snakemake --dag -s bwa_align.smk sorted_reads/{A,B,C}.bam.bai | dot -Tsvg > dag.svg
```

And also the rulegraph

```{bash}
snakemake --rulegraph -s bwa_align.smk sorted_reads/{A,B,C}.bam.bai | dot -Tsvg > rulegraph.svg
```

as well as a dry-run (remember to delete files that have been generated already beforehand, in case it does not want to do anything)

```{bash}
snakemake -s bwa_align.smk sorted_reads/{A,B,C}.bam.bai -np
```

# Exercise 6

Add the variant calling step. Where do you need to define the `SAMPLES` object? What target rule do you need to give to the call?

Before executing your code, do a dry-run and create the rulegraph and dag!

The workflow would look like this:

```{python}
SAMPLES = ["A", "B"]

rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:"""
      samtools sort -T sorted_reads/{wildcards.sample} \
               -O bam {input} > {output}
    """

rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"

rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES)
    output:
        "calls/all.vcf"
    shell:
        "bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"
```

And you can do the dry-run by running

```{bash}
snakemake -s bwa_align.smk calls/all.vcf -np
```

and the rulegraph like this

```{bash}
snakemake --rulegraph -s bwa_align.smk calls/all.vcf | dot -Tsvg > rulegraph_vcf.svg
snakemake --dag -s bwa_align.smk calls/all.vcf | dot -Tsvg > dag_vcf.svg
```

# Exercise 7
Add your own script file (like the quality histogram) to your workflow and rerun it to create the figure.

The full workflow will look like this

```{python}
SAMPLES = ["A", "B"]

rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:"""
      samtools sort -T sorted_reads/{wildcards.sample} \
               -O bam {input} > {output}
    """

rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"

rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES)
    output:
        "calls/all.vcf"
    shell:
        "bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"

rule plot_quals:
    input:
        "calls/all.vcf"
    output:
        "plots/quals.svg"
    script:
        "scripts/plot-quals.py"
```

and you can start it with

```{bash}
snakemake -c1 -s bwa_align.smk plots/quals.svg
```

Again, create also a dag-plot for the workflow

```{bash}
snakemake --dag -s bwa_align.smk plots/quals.svg | dot -Tsvg > all.svg
```

# Exercise 8
Add the target rule `all` to the workflow and rerun the pipeline using it

This is how the complete workflow look like now:
```{python}
SAMPLES = ["A", "B"]

rule all:
    input:
        "plots/quals.svg"

rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:"""
      samtools sort -T sorted_reads/{wildcards.sample} \
               -O bam {input} > {output}
    """

rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"

rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES)
    output:
        "calls/all.vcf"
    shell:
        "bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"

rule plot_quals:
    input:
        "calls/all.vcf"
    output:
        "plots/quals.svg"
    script:
        "scripts/plot-quals.py"
``` 

and we can run this workflow now such that all rules are execute by typing

```{bash}
snakemake -c1 -s bwa_align.smk
```

# Exercise 9

Change the number of threads in the rule `bwa_map`according to your machine.

It would look e.g. like this then:

```{python}
rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    threads: 8
    shell:
        "bwa mem -t {threads} {input} | samtools view -Sb - > {output}"
```

Then, rerun your workflow using different amount of threads provided. You can force snakemake to rerun an entire workflow by using the option `--forceall` in the `snakemake`-call:

```{bash}
snakemake -c2 -s bwa_align.smk --forceall
```

# Exercise 10

## Repeat config file confiration from slides
Create a configuration file for your workflow for samples A and B, adjust the workflow to use it-

The configration would look like this

```{python}
samples:
    A: data/samples/A.fastq
    B: data/samples/B.fastq
``` 

and the workflow like this

```{python}
rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=config["samples"]),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=config["samples"])
    output:
        "calls/all.vcf"
    shell:
        "bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"
```

## Extend the configuration

Now, create a new configuration, e.g. called config2.yaml, including sample C.

It will look like this

```{python}
samples:
    A: data/samples/A.fastq
    B: data/samples/B.fastq
    C: data/samples/C.fastq
```

Then rerun the workflow using the new configfile, using the `--configfile option`

```{bash}
snakemake -c1 -s bwa_align.smk --configfile config2.yaml --forceall -np
```

## Add more keys

Remove the hardcoded genome from your worflow and add its path into the configuration file.

The new configuration file looks like this:

```{python}
genome: "data/genome.fa"

samples:
    A: data/samples/A.fastq
    B: data/samples/B.fastq
    C: data/samples/C.fastq

```

And the relevant parts of the updated workflow

```{python}
rule bwa_map:
    input:
        config["genome"],
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"
```

# Exercise 11

Define a python function as input for bwa_map that makes use of the information in the configfile

This is how the relevant parts of the workflow look like:

```{python}
def get_bwa_map_input_fastqs(wildcards):
    return config["samples"][wildcards.sample]

rule bwa_map:
    input:
        config["genome"],
        get_bwa_map_input_fastqs
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

```

# Exercise 12

Define the option `prior_mutation_rate` with values `0.001` in the config file and pass it as parameter to the `bcftools_call` rule, so that effectively this command is executed:

`
bcftools call -mv -P 0.001 - >
` 

The config file would like this this:

```{python}
genome: "data/genome.fa"

prior_mutation_rate: 0.001

samples:
    A: data/samples/A.fastq
    B: data/samples/B.fastq
    C: data/samples/C.fastq
```

and the relevant rule in the workflow:

```{python}
rule bcftools_call:
    input:
        fa=config["genome"],
        bam=expand("sorted_reads/{sample}.bam", sample=config["samples"]),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=config["samples"])
    output:
        "calls/all.vcf"
    params:
        rate=config["prior_mutation_rate"]
    shell:
        "(bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv -P {params.rate} - > {output})"
```

# Exercise 13
Add also a log directive to the `bcftools_call` directive

The updated `bcftools_call` function looks like this:

```{python}
rule bcftools_call:
    input:
        fa=config["genome"],
        bam=expand("sorted_reads/{sample}.bam", sample=config["samples"]),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=config["samples"])
    output:
        "calls/all.vcf"
    params:
        rate=config["prior_mutation_rate"]
    log:
        "logs/bcftools_call/all.log"
    shell:
        "(bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv -P {params.rate} - > {output}) 2> {log}"
```

Print the `summary` table for your workflow, touch some input files and redo the summary.

Command to run the summary:

```{bash}
snakemake -c4 -s bwa_align.smk --configfile config.yaml --summary
```

# Exercise 14

Add the temp and protected functions to your workflow and check how snakemake behaves.

Rerun the workflow and check, if snakemake allows you to overwrite the created and protected files.
